{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae657a3e-d12e-4edb-8d51-bb9cffc52c4a",
   "metadata": {},
   "source": [
    "# Using Python to create a work flow, using ChatGPT api to convert document to tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06affac-17f4-4b98-8eb2-638d00f60696",
   "metadata": {},
   "source": [
    "### key note:\n",
    "-because it is a LLM model, it doesn't work that well when the size of file is large\n",
    "\n",
    "-ideally we should segrete tasks into smaller element\n",
    "\n",
    "-in this particular case, pdfplumber or other similar packages might be better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f589bcdd-d8d5-4c1f-a0b1-65e0f4dada99",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "First, make sure the OpenAI API works...\n",
    "- here i manually altered the environment used in this local file. it changes everytime I open the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b044c9f7-934a-4cf8-801d-c231521eecb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\46798566\\AppData\\Local\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "print(sys.executable)\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"My key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94792f0f-2e41-4ef9-8334-63ebea3e9aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "864cea12-be42-4c3d-ba04-827c7528c193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1\n",
    "print('lin')\n",
    "print('lin222')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d180978-1491-4844-a151-2a6595d6f1cb",
   "metadata": {},
   "source": [
    "- simply test if the OpenAI works or not...  if this package is not installed, simply try: %pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "30c48410-df9a-4943-880b-5a540f3aefa5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 11, 1412, 939, 357, 5306]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4.1-mini\")\n",
    "text = \"I, what am I doing\" \n",
    "tokens = enc.encode(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f986b30e-ce56-47b7-932a-2743144a6eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = client.responses.create(\n",
    "    model=\"gpt-5.1\",\n",
    "    input=\"Say hello in one sentence.\"\n",
    ")\n",
    "\n",
    "print(resp.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd1b9c4-e8c5-4058-aa9b-24b249abfb83",
   "metadata": {},
   "source": [
    " if this package is not installed, simply try: %pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165da110-a29d-4434-b00a-28c73760b056",
   "metadata": {},
   "source": [
    "- choose all the files that I want to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01ae1622-c138-4831-a299-16f53ab610da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "directory = r\"C:\\Users\\46798566/Box\\Py_codes\\TexasCourt\\Book\\Attorney_list\"\n",
    "den_files = (\n",
    "            glob.glob(os.path.join(directory, \"AttorneyPopulationDensity*.pdf\")) +\n",
    "            glob.glob(os.path.join(directory, \"PopulationDensityReport*.pdf\"))\n",
    "            )\n",
    "#pdf_text = open(\"extracted_text.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a39af66a-bee8-4e9e-a4ac-013e74ce325e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296761\n"
     ]
    }
   ],
   "source": [
    "# with open(upload_file, \"rb\") as f:\n",
    "#     data = f.read()\n",
    "# print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea3199c-174d-4d74-8a96-30b3fcbfd31e",
   "metadata": {},
   "source": [
    "Here is the most important part, setting up the prompt! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4c95f70-6484-4a47-ad94-87035811d366",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "client = OpenAI()\n",
    "prompt = \"\"\"\n",
    "Extract tables from the PDF.\n",
    "\n",
    "Rules:\n",
    "- Keep ONLY rows that are counties, exclude MSAs and other non related rows\n",
    "- Ignore any MSA / Metro / CBSA rows.\n",
    "- Extract all 254 counties, each county as a row\n",
    "- Convert the result as a csv file so it is easy to convert\n",
    "- Use EXACTLY these keys for each record, leave the record as NA if you can not find the record\n",
    "[\n",
    "  {\n",
    "    \"county name\": \"Hardin County\",\n",
    "    \"active in state texas attorney\": \"59\",\n",
    "    \"population\": \"1,275,648\",       # here in the table in the pdf, Texas population means the population in that county\n",
    "    \"ratio of attorney to population\": \"1:508\",\n",
    "    \"attorney as a percentage of total in state attorney\",  \"0.92%\"\n",
    "  }\n",
    "]\n",
    "\n",
    "Notes:\n",
    "- “Texas population” in the table means the population in that county.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# upload_file = den_files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f59960a-d72d-4604-89f7-de7715a867f1",
   "metadata": {},
   "source": [
    "Before upload all the files, upload one and do a test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e7f9e5f-3b25-4b36-93e2-465cd69a5371",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# upload one file first\n",
    "upload_file = den_files[6]\n",
    "uploaded0 = client.files.create(\n",
    "    file=open(upload_file, \"rb\"),\n",
    "    purpose=\"user_data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d8404b-56da-4ed9-8177-81b4321b6e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = client.responses.create(\n",
    "    model=\"gpt-5.2\",\n",
    "    input=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"input_file\", \"file_id\": uploaded0.id},\n",
    "            {\"type\": \"input_text\", \"text\": prompt},\n",
    "        ],\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c04feb2-9e5b-4dc8-a129-ce507fdb4d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = resp.output_text\n",
    "df = pd.read_json(StringIO(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "37e63c0d-d89d-4d36-91f6-e00c70e63853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if it works..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37178f0-c699-4d0e-acfb-891508364c5e",
   "metadata": {},
   "source": [
    "Here I set up the OpenAI environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040015d7-a5a2-4d84-bc78-15f5801992bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# upload all the legit files, as a list\n",
    "uploaded_file_list = []\n",
    "for upload_file in den_files[0:4]:    # only selected the first four files to save tokens....\n",
    "    print('here is file', upload_file, \"being uploaded\")\n",
    "    uploaded = client.files.create(\n",
    "        file=open(upload_file, \"rb\"),\n",
    "        purpose=\"user_data\",\n",
    "    )\n",
    "    uploaded_file_list.append(uploaded)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd496f7-c491-4211-a46f-e4b5a87766b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload_file = uploaded_file_list[0]\n",
    "response_list = []\n",
    "table_list = []\n",
    "for uploaded_file in uploaded_file_list:\n",
    "    resp = client.responses.create(\n",
    "        model=\"gpt-5.2\",\n",
    "        input=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_file\", \"file_id\": uploaded_file.id},\n",
    "                {\"type\": \"input_text\", \"text\": prompt},\n",
    "            ],\n",
    "        }],\n",
    "    )\n",
    "    response_list.append(resp)\n",
    "    print('We have got our response for file',uploaded_file.filename,'back!')\n",
    "\n",
    "    # the following lines, hopefully will extract the data within that table and convert them to a data frame\n",
    "    data = resp.output_text\n",
    "    df = pd.read_json(StringIO(data))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d65b861-245b-43d2-8976-4ccdb68a5947",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads( response_list[3].output_text )\n",
    "print(data)\n",
    "pd.DataFrame(data)\n",
    "df = pd.DataFrame(data[\"data_found_in_provided_content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7e6c6a55-faee-4f97-872a-1a3767e7a62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n  {\\n    \"county name\": null,\\n    \"active in state texas attorney\": null,\\n    \"population\": null,\\n    \"ratio of attorney to population\": null,\\n    \"attorney as a percentage of total in state attorney\": null\\n  }\\n]'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_list[0].output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc370f5-a954-4587-97fc-3bc575764004",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_list[0] = data_found_in_provided_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c903d0d1-1d00-4599-9d88-bf870e5d4fc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Wrap the literal string in a StringIO object\n",
    "# This makes pandas read the string as if it were a file\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import json\n",
    "\n",
    "try:\n",
    "    df = pd.read_json(StringIO(data))\n",
    "except ValueError as e:\n",
    "    # If the JSON is not valid (e.g. single quotes), you might need json.loads first\n",
    "    # and then create a DataFrame\n",
    "    data = json.loads(json_string_data)\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv(\"county_stats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaf25d8-f24a-4e2c-be6c-41c840c5a3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20bb7875-7e63-438e-89e6-309f08f24119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\46798566\\\\AppData\\\\Local\\\\anaconda3\\\\python313.zip',\n",
       " 'C:\\\\Users\\\\46798566\\\\AppData\\\\Local\\\\anaconda3\\\\DLLs',\n",
       " 'C:\\\\Users\\\\46798566\\\\AppData\\\\Local\\\\anaconda3\\\\Lib',\n",
       " 'C:\\\\Users\\\\46798566\\\\AppData\\\\Local\\\\anaconda3',\n",
       " '',\n",
       " 'C:\\\\Users\\\\46798566\\\\AppData\\\\Local\\\\anaconda3\\\\Lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\46798566\\\\AppData\\\\Local\\\\anaconda3\\\\Lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\46798566\\\\AppData\\\\Local\\\\anaconda3\\\\Lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\46798566\\\\AppData\\\\Local\\\\anaconda3\\\\Lib\\\\site-packages\\\\Pythonwin']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba27c59-8dd0-4494-985f-a88a477a567f",
   "metadata": {},
   "source": [
    "## Advantage: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71cd5cd-d0c1-483c-846e-752a072c346a",
   "metadata": {},
   "source": [
    "# what I am doing here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3e5ddb-18e1-4aa1-9258-6a03b000d1ef",
   "metadata": {},
   "source": [
    "## Disdvantage: \n",
    "- not sure why it is always slower than manual gpt input"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyCharm Env)",
   "language": "python",
   "name": "pycharm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
