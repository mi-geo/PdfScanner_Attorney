{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae657a3e-d12e-4edb-8d51-bb9cffc52c4a",
   "metadata": {},
   "source": [
    "# Using Python to create a work flow, using ChatGPT api to convert document to tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0730b772-6bc1-401d-93d1-48750f4eed89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\46798566\\\\AppData\\\\Local\\\\anaconda3\\\\python.exe'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9ac5d7c-6eb8-4aae-9cc8-f1b78cbb9402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06affac-17f4-4b98-8eb2-638d00f60696",
   "metadata": {},
   "source": [
    "here i manually altered the environment used in this local file. it changes everytime I open the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b044c9f7-934a-4cf8-801d-c231521eecb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94792f0f-2e41-4ef9-8334-63ebea3e9aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "450e2e36-69af-4e0b-be21-29574e5f5647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncPage[Model](data=[Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'), Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'), Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'), Model(id='gpt-5.2-chat-latest', created=1765344352, object='model', owned_by='system'), Model(id='gpt-5.2-2025-12-11', created=1765313028, object='model', owned_by='system'), Model(id='gpt-5.2', created=1765313051, object='model', owned_by='system'), Model(id='gpt-5.2-pro-2025-12-11', created=1765343959, object='model', owned_by='system'), Model(id='gpt-5.2-pro', created=1765343983, object='model', owned_by='system'), Model(id='davinci-002', created=1692634301, object='model', owned_by='system'), Model(id='babbage-002', created=1692634615, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'), Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'), Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'), Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'), Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'), Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'), Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'), Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'), Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'), Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'), Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'), Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system'), Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system'), Model(id='gpt-4o', created=1715367049, object='model', owned_by='system'), Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system'), Model(id='gpt-4o-mini-2024-07-18', created=1721172717, object='model', owned_by='system'), Model(id='gpt-4o-mini', created=1721172741, object='model', owned_by='system'), Model(id='gpt-4o-2024-08-06', created=1722814719, object='model', owned_by='system'), Model(id='chatgpt-4o-latest', created=1723515131, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview', created=1727460443, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview', created=1727659998, object='model', owned_by='system'), Model(id='omni-moderation-latest', created=1731689265, object='model', owned_by='system'), Model(id='omni-moderation-2024-09-26', created=1732734466, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview-2024-12-17', created=1733945430, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview-2024-12-17', created=1734034239, object='model', owned_by='system'), Model(id='gpt-4o-mini-realtime-preview-2024-12-17', created=1734112601, object='model', owned_by='system'), Model(id='gpt-4o-mini-audio-preview-2024-12-17', created=1734115920, object='model', owned_by='system'), Model(id='o1-2024-12-17', created=1734326976, object='model', owned_by='system'), Model(id='o1', created=1734375816, object='model', owned_by='system'), Model(id='gpt-4o-mini-realtime-preview', created=1734387380, object='model', owned_by='system'), Model(id='gpt-4o-mini-audio-preview', created=1734387424, object='model', owned_by='system'), Model(id='o3-mini', created=1737146383, object='model', owned_by='system'), Model(id='o3-mini-2025-01-31', created=1738010200, object='model', owned_by='system'), Model(id='gpt-4o-2024-11-20', created=1739331543, object='model', owned_by='system'), Model(id='gpt-4o-search-preview-2025-03-11', created=1741388170, object='model', owned_by='system'), Model(id='gpt-4o-search-preview', created=1741388720, object='model', owned_by='system'), Model(id='gpt-4o-mini-search-preview-2025-03-11', created=1741390858, object='model', owned_by='system'), Model(id='gpt-4o-mini-search-preview', created=1741391161, object='model', owned_by='system'), Model(id='gpt-4o-transcribe', created=1742068463, object='model', owned_by='system'), Model(id='gpt-4o-mini-transcribe', created=1742068596, object='model', owned_by='system'), Model(id='o1-pro-2025-03-19', created=1742251504, object='model', owned_by='system'), Model(id='o1-pro', created=1742251791, object='model', owned_by='system'), Model(id='gpt-4o-mini-tts', created=1742403959, object='model', owned_by='system'), Model(id='o3-2025-04-16', created=1744133301, object='model', owned_by='system'), Model(id='o4-mini-2025-04-16', created=1744133506, object='model', owned_by='system'), Model(id='o3', created=1744225308, object='model', owned_by='system'), Model(id='o4-mini', created=1744225351, object='model', owned_by='system'), Model(id='gpt-4.1-2025-04-14', created=1744315746, object='model', owned_by='system'), Model(id='gpt-4.1', created=1744316542, object='model', owned_by='system'), Model(id='gpt-4.1-mini-2025-04-14', created=1744317547, object='model', owned_by='system'), Model(id='gpt-4.1-mini', created=1744318173, object='model', owned_by='system'), Model(id='gpt-4.1-nano-2025-04-14', created=1744321025, object='model', owned_by='system'), Model(id='gpt-4.1-nano', created=1744321707, object='model', owned_by='system'), Model(id='gpt-image-1', created=1745517030, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview-2025-06-03', created=1748907838, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview-2025-06-03', created=1748908498, object='model', owned_by='system'), Model(id='gpt-4o-transcribe-diarize', created=1750798887, object='model', owned_by='system'), Model(id='gpt-5-chat-latest', created=1754073306, object='model', owned_by='system'), Model(id='gpt-5-2025-08-07', created=1754075360, object='model', owned_by='system'), Model(id='gpt-5', created=1754425777, object='model', owned_by='system'), Model(id='gpt-5-mini-2025-08-07', created=1754425867, object='model', owned_by='system'), Model(id='gpt-5-mini', created=1754425928, object='model', owned_by='system'), Model(id='gpt-5-nano-2025-08-07', created=1754426303, object='model', owned_by='system'), Model(id='gpt-5-nano', created=1754426384, object='model', owned_by='system'), Model(id='gpt-audio-2025-08-28', created=1756256146, object='model', owned_by='system'), Model(id='gpt-realtime', created=1756271701, object='model', owned_by='system'), Model(id='gpt-realtime-2025-08-28', created=1756271773, object='model', owned_by='system'), Model(id='gpt-audio', created=1756339249, object='model', owned_by='system'), Model(id='gpt-5-codex', created=1757527818, object='model', owned_by='system'), Model(id='gpt-image-1-mini', created=1758845821, object='model', owned_by='system'), Model(id='gpt-5-pro-2025-10-06', created=1759469707, object='model', owned_by='system'), Model(id='gpt-5-pro', created=1759469822, object='model', owned_by='system'), Model(id='gpt-audio-mini', created=1759512027, object='model', owned_by='system'), Model(id='gpt-audio-mini-2025-10-06', created=1759512137, object='model', owned_by='system'), Model(id='gpt-5-search-api', created=1759514629, object='model', owned_by='system'), Model(id='gpt-realtime-mini', created=1759517133, object='model', owned_by='system'), Model(id='gpt-realtime-mini-2025-10-06', created=1759517175, object='model', owned_by='system'), Model(id='sora-2', created=1759708615, object='model', owned_by='system'), Model(id='sora-2-pro', created=1759708663, object='model', owned_by='system'), Model(id='gpt-5-search-api-2025-10-14', created=1760043960, object='model', owned_by='system'), Model(id='gpt-5.1-chat-latest', created=1762547951, object='model', owned_by='system'), Model(id='gpt-5.1-2025-11-13', created=1762800353, object='model', owned_by='system'), Model(id='gpt-5.1', created=1762800673, object='model', owned_by='system'), Model(id='gpt-5.1-codex', created=1762988221, object='model', owned_by='system'), Model(id='gpt-5.1-codex-mini', created=1763007109, object='model', owned_by='system'), Model(id='gpt-5.1-codex-max', created=1763671532, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'), Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'), Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'), Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal')], object='list')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f986b30e-ce56-47b7-932a-2743144a6eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!\n"
     ]
    }
   ],
   "source": [
    "resp = client.responses.create(\n",
    "    model=\"gpt-5.1\",\n",
    "    input=\"Say hello in one sentence.\"\n",
    ")\n",
    "\n",
    "print(resp.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd1b9c4-e8c5-4058-aa9b-24b249abfb83",
   "metadata": {},
   "source": [
    " if this package is not installed, simply try: %pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acd784c6-7053-4e30-a1e1-a244acc284a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseModel.dict of Response(id='resp_041430c8a7b4bec700693cd59c004c819ea24d325ca281f697', created_at=1765594524.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5.2-2025-12-11', object='response', output=[ResponseOutputMessage(id='msg_041430c8a7b4bec700693cd59c8e90819ea6ce104f4c093a04', content=[ResponseOutputText(annotations=[], text='Hello!', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=0.98, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, prompt_cache_retention=None, reasoning=Reasoning(effort='none', generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=12, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=6, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=18), user=None, billing={'payer': 'developer'}, store=True)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01c01f2a-a3ce-4d71-a3d6-9bee7656d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "import pdfplumber\n",
    "print(upload_file)\n",
    "with pdfplumber.open(upload_file) as pdf:\n",
    "    for i, page in enumerate(pdf.pages[:2]):\n",
    "        print(f\"--- Page {i+1} ---\")\n",
    "        print(page.extract_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d0268912-03b7-4cc1-863a-1c120c67c32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Page 1 ---\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "with pdfplumber.open(upload_file) as pdf:\n",
    "    for i, page in enumerate(pdf.pages[1:2]):\n",
    "        print(f\"--- Page {i+1} ---\")\n",
    "        print(page.extract_tables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96560ae3-81d3-4c29-86cc-36eae1f4d461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2014 Attorney Population Density by Metropolitan Statistical Area\\nS B T\\nTATE AR OF EXAS\\nD R & A\\nEPARTMENT OF ESEARCH NALYSIS\\nATTORNEY POPULATION DENSITY BY METROPOLITAN STATISTICAL AREA\\n2014-15\\nFor more information, contact:\\nState Bar of Texas\\nDepartment of Research and Analysis\\nP.O. Box 12487\\nAustin, TX 78711-2487\\n(800) 204-2222 ext. 1724\\nresearch@texasbar.com\\nwww.texasbar.com/research\\nState Bar of Texas Department of Research and Analysis'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = pdf.pages[0]\n",
    "page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b7613def-acb3-402c-9102-2a42955b3689",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'start_page' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 15\u001b[0m\n\u001b[0;32m      2\u001b[0m table_settings \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical_strategy\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlines\u001b[39m\u001b[38;5;124m\"\u001b[39m,     \u001b[38;5;66;03m# try \"text\" if this fails\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhorizontal_strategy\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlines\u001b[39m\u001b[38;5;124m\"\u001b[39m,   \u001b[38;5;66;03m# try \"text\" if this fails\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeep_blank_chars\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     12\u001b[0m }\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pdfplumber\u001b[38;5;241m.\u001b[39mopen(upload_file) \u001b[38;5;28;01mas\u001b[39;00m pdf:\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_page \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, end_page):  \u001b[38;5;66;03m# 0-based index\u001b[39;00m\n\u001b[0;32m     16\u001b[0m         page \u001b[38;5;241m=\u001b[39m pdf\u001b[38;5;241m.\u001b[39mpages[p]\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;66;03m# Extract tables from the page\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'start_page' is not defined"
     ]
    }
   ],
   "source": [
    "# table_settings: tweak these if needed\n",
    "table_settings = {\n",
    "    \"vertical_strategy\": \"lines\",     # try \"text\" if this fails\n",
    "    \"horizontal_strategy\": \"lines\",   # try \"text\" if this fails\n",
    "    \"intersection_tolerance\": 5,\n",
    "    \"snap_tolerance\": 3,\n",
    "    \"join_tolerance\": 3,\n",
    "    \"edge_min_length\": 3,\n",
    "    \"min_words_vertical\": 1,\n",
    "    \"min_words_horizontal\": 1,\n",
    "    \"keep_blank_chars\": False,\n",
    "}\n",
    "\n",
    "with pdfplumber.open(upload_file) as pdf:\n",
    "    for p in range(start_page - 1, end_page):  # 0-based index\n",
    "        page = pdf.pages[p]\n",
    "\n",
    "        # Extract tables from the page\n",
    "        tables = page.extract_tables(table_settings=table_settings)\n",
    "\n",
    "        for t_idx, t in enumerate(tables):\n",
    "            # t is a list of rows; each row is a list of cells\n",
    "            df = pd.DataFrame(t)\n",
    "\n",
    "            # optional cleanup: drop fully empty rows\n",
    "            df = df.dropna(how=\"all\")\n",
    "            df = df.loc[~(df.astype(str).apply(lambda r: \"\".join(r).strip() == \"\", axis=1))]\n",
    "\n",
    "            df[\"__page__\"] = p + 1\n",
    "            df[\"__table__\"] = t_idx + 1\n",
    "            all_tables.append(df)\n",
    "\n",
    "print(f\"Extracted {len(all_tables)} tables from pages {start_page}-{end_page}.\")\n",
    "\n",
    "out_dir = r\"C:\\Users\\46798566\\Downloads\"\n",
    "for i, df in enumerate(all_tables, 1):\n",
    "    out_path = fr\"{out_dir}\\tables_p{df['__page__'].iloc[0]}_t{i}.csv\"\n",
    "    df.to_csv(out_path, index=False)\n",
    "print(\"Saved CSVs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d726b024-0973-4dc5-8ce3-666160b0704e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pdfplumber\u001b[38;5;241m.\u001b[39mopen(pdf_path) \u001b[38;5;28;01mas\u001b[39;00m pdf:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_page \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, end_page):\n\u001b[1;32m---> 40\u001b[0m         page \u001b[38;5;241m=\u001b[39m pdf\u001b[38;5;241m.\u001b[39mpages[p]\n\u001b[0;32m     41\u001b[0m         tables \u001b[38;5;241m=\u001b[39m page\u001b[38;5;241m.\u001b[39mextract_tables(table_settings\u001b[38;5;241m=\u001b[39mtable_settings) \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tables) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "pdf_path = r\"C:\\Users\\46798566\\Downloads\\AttorneyPopulationDensity2014-15.pdf\"\n",
    "out_csv  = r\"C:\\Users\\46798566\\Downloads\\AttorneyPopulationDensity2014-15_pages14-20_combined.csv\"\n",
    "out_notable = r\"C:\\Users\\46798566\\Downloads\\AttorneyPopulationDensity2014-15_pages14-20_no_table_pages.txt\"\n",
    "\n",
    "start_page = 14\n",
    "end_page   = 20  # inclusive\n",
    "\n",
    "table_settings = {\n",
    "    \"vertical_strategy\": \"lines\",\n",
    "    \"horizontal_strategy\": \"lines\",\n",
    "    \"intersection_tolerance\": 5,\n",
    "    \"snap_tolerance\": 3,\n",
    "    \"join_tolerance\": 3,\n",
    "    \"edge_min_length\": 3,\n",
    "}\n",
    "\n",
    "def clean_df_from_table(table):\n",
    "    df = pd.DataFrame(table)\n",
    "    df = df.dropna(how=\"all\").dropna(axis=1, how=\"all\")\n",
    "    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "    # Use first row as header if it looks header-ish\n",
    "    if len(df) >= 2:\n",
    "        header = df.iloc[0].tolist()\n",
    "        if sum(bool(h) for h in header) >= sum(bool(x) for x in df.iloc[1].tolist()):\n",
    "            df.columns = header\n",
    "            df = df.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "all_parts = []\n",
    "no_table_pages = []\n",
    "canonical_cols = None\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for p in range(start_page - 1, end_page):\n",
    "        page = pdf.pages[p]\n",
    "        tables = page.extract_tables(table_settings=table_settings) or []\n",
    "\n",
    "        if len(tables) == 0:\n",
    "            no_table_pages.append(p + 1)  # human page number\n",
    "            continue\n",
    "\n",
    "        for t in tables:\n",
    "            df = clean_df_from_table(t)\n",
    "            if df.empty:\n",
    "                continue\n",
    "\n",
    "            if canonical_cols is None:\n",
    "                canonical_cols = list(df.columns)\n",
    "\n",
    "            # Drop repeated header rows (multi-page table)\n",
    "            if canonical_cols and len(df.columns) == len(canonical_cols):\n",
    "                header_row_mask = df.apply(\n",
    "                    lambda r: [str(x) for x in r.tolist()] == [str(c) for c in canonical_cols],\n",
    "                    axis=1\n",
    "                )\n",
    "                df = df.loc[~header_row_mask].reset_index(drop=True)\n",
    "\n",
    "            df[\"__page__\"] = p + 1\n",
    "            all_parts.append(df)\n",
    "\n",
    "combined = pd.concat(all_parts, ignore_index=True, sort=False) if all_parts else pd.DataFrame()\n",
    "combined.to_csv(out_csv, index=False)\n",
    "\n",
    "with open(out_notable, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Pages with NO tables detected:\\n\")\n",
    "    f.write(\", \".join(map(str, no_table_pages)) if no_table_pages else \"None\")\n",
    "\n",
    "# Minimal status (remove these two lines if you want total silence)\n",
    "print(\"Saved CSV:\", out_csv)\n",
    "print(\"No-table pages:\", no_table_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6968ef-5c4b-461c-95d5-c479b65969e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "30c48410-df9a-4943-880b-5a540f3aefa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 11, 1412, 939, 357, 5306]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4.1-mini\")\n",
    "text = \"I, what am I doing\" \n",
    "tokens = enc.encode(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01ae1622-c138-4831-a299-16f53ab610da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "directory = \"C:/Users/46798566/Downloads\"\n",
    "den_files = (\n",
    "            glob.glob(os.path.join(directory, \"AttorneyPopulationDensity*-*\")) +\n",
    "            glob.glob(os.path.join(directory, \"PopulationDensityReport*-*\"))\n",
    "            )\n",
    "upload_file = den_files[1]\n",
    "#pdf_text = open(\"extracted_text.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a39af66a-bee8-4e9e-a4ac-013e74ce325e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296761\n"
     ]
    }
   ],
   "source": [
    "with open(upload_file, \"rb\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307863a4-80e7-4e59-a6c3-d642ddfbacee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "upload_file = den_files[0]\n",
    "\n",
    "prompt = \"\"\"\n",
    "Extract tables from the PDF.\n",
    "\n",
    "Rules:\n",
    "- Keep ONLY rows for counties.\n",
    "- Ignore any MSA / Metro / CBSA rows.\n",
    "- Return JSON with this shape:\n",
    "\n",
    "[\n",
    "  {\n",
    "    \"county name\": \"Hardin County\",\n",
    "    \"active in state texas attorney\": \"59\",\n",
    "    \"population\": \"1,275,648\",       # here in the table in the pdf, Texas population means the population in that county\n",
    "    \"ratio of attorney to population\": \"1:508\",\n",
    "    \"attorney as a percentage of total in state attorney\",\n",
    "  }\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-5.2\",\n",
    "    input=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"input_file\", \"file_id\": upload_file},\n",
    "            {\"type\": \"input_text\", \"text\": prompt},\n",
    "        ],\n",
    "    }],\n",
    ")\n",
    "\n",
    "# \n",
    "data = resp.output_text\n",
    "df = pd.read_json(data)\n",
    "df.to_csv(\"county_stats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c903d0d1-1d00-4599-9d88-bf870e5d4fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba200160-f545-40ee-933b-7bc67dfe97ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Extract (structured JSON output)\n",
    "prompt = \"\"\"\n",
    "Extract the table(s) of statistics from this PDF.\n",
    "\n",
    "Rules:\n",
    "- Keep ONLY rows where the geography is a COUNTY (e.g., name contains 'County' or clearly corresponds to a county).\n",
    "- IGNORE any MSA / Metropolitan Statistical Area / Metro / CBSA sections and rows.\n",
    "- Preserve all numeric columns for each county as key/value pairs in `stats`.\n",
    "- If the table has a title/header, put it in `source_table_title`.\n",
    "\"\"\"\n",
    "\n",
    "resp = client.responses.parse(\n",
    "    model=\"gpt-5\",  # or another model you use\n",
    "    input=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"input_file\", \"file_id\": uploaded.id},\n",
    "            {\"type\": \"input_text\", \"text\": prompt},\n",
    "        ],\n",
    "    }],\n",
    "    text_format=CountyTable,   # Structured Outputs (parsed into Pydantic)\n",
    ")\n",
    "\n",
    "data = resp.output_parsed\n",
    "print(\"Tokens:\", resp.usage)\n",
    "print(\"Counties extracted:\", len(data.counties))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71cd5cd-d0c1-483c-846e-752a072c346a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# what I am doing here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f2e8af7-78b5-4d5e-911f-f7a3df141d45",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'defaultdict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m defaultdict(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'defaultdict' is not defined"
     ]
    }
   ],
   "source": [
    "defaultdict(lambda: float('inf'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyCharm Env)",
   "language": "python",
   "name": "pycharm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
